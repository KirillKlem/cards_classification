{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce2c455-94ec-4fea-a333-6da68d382ba1",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41436d-1596-4dc9-ba42-8dfe84725974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from load_data import train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb3cc6-addf-4d42-bb6f-e59642b097e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of classes\n",
    "for _, labels in train_ds:\n",
    "    num_classes = len(labels[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1495f-6b39-4a39-8f2a-3ad2d80567a2",
   "metadata": {},
   "source": [
    "## 2. Create a base case that needs to be surpassed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1db2ae-54c0-4287-9e8d-223f3b9b88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(dataset, num_classes):\n",
    "    random_predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for _, labels in dataset:\n",
    "        batch_size = labels.shape[0]\n",
    "        random_preds = np.random.randint(0, num_classes, size=batch_size)\n",
    "        random_predictions.extend(random_preds)\n",
    "        \n",
    "        true_labels.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    \n",
    "    return np.array(random_predictions), np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ed977-9d1c-49f6-8031-cedb62476648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_random_classifier(random_predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, random_predictions)\n",
    "    print(f'Random Classifier Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31d1c8-b48a-4c81-bd56-05a6a3799d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_predictions, true_labels = random_classifier(train_ds, num_classes)\n",
    "evaluate_random_classifier(random_predictions, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb9de5-ceb4-44a4-b783-015c0123b794",
   "metadata": {},
   "source": [
    "## 3. Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fa4ca-3667-477b-8e35-485714b7b82c",
   "metadata": {},
   "source": [
    "**I will use fine-tuning due to the small amount of computer power. Let's take the ConvNext model (Tiny version) as a basis, other high-quality options: Vit, swin, BEiT, EfficientNet. Then I will finish training the model on my data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78588bb4-5173-4c3a-9c0c-d9c8f7f1d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.ConvNeXtTiny(\n",
    "    model_name=\"convnext_tiny\",\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape = (224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9968e9-211c-483d-889b-800c1dc720a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.GlobalAveragePooling2D()(conv_base.output)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = keras.Model(inputs=conv_base.input, \n",
    "                    outputs=outputs, \n",
    "                    name='cards_classification')\n",
    "\n",
    "#Freeze the layers of the base model\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11582c89-7e44-4f7d-842d-2bab4534a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf161920-f29f-468e-9f8f-89a6637eb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import AdamW\n",
    "\n",
    "#Use categorical_crossentropy, because the data was encoded using categorical label mode\n",
    "#The reason for using a low learning rate is the need to limit the amount of changes made\n",
    "#to the representations of the three pre-trained layers. Making too many changes can damage these views.\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=AdamW(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48398a1-5811-40d4-9a68-1ad6cf3d80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#use callbacks to save the model at the optimal point\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "    filepath='cards_classification.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7ce0-9af6-4fc8-a2a0-cd71a0105bbf",
   "metadata": {},
   "source": [
    "## 4. Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb27be-0b0f-4de0-83eb-e8e9f096da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50481cae-247a-4d99-8e44-259c6bb70bf0",
   "metadata": {},
   "source": [
    "## 5. Visualization of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd771c7-ec67-4529-af8c-5b86f73bb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Graph of losses at the training and validation stage\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Losses at the training stage\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Losses at the validation stage\")\n",
    "plt.title(\"Losses at the training and validation stage\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab908bc4-3aa2-4da7-96f8-c49e5f5c06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf() \n",
    "\n",
    "#Graph of accuracy at the training and validation stage\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Accuracy at the training stage\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Accuracy at the validation stage\")\n",
    "plt.title(\"Accuracy at the training and validation stage\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7911f-053e-4042-8e53-8cedb21288e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
